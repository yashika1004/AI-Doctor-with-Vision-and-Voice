
ğŸ©º AI Doctor with Vision & Voice (VocDoc)

AI Doctor with Vision & Voice is a multimodal AI-powered medical assistant that allows users to speak their symptoms and upload medical images.
The system analyzes voice + vision inputs and responds like a virtual doctor with text-based and spoken medical insights using advanced generative AI models.

ğŸš€ Features

ğŸ¤ Speech-to-Text (STT) using Whisper (via Groq API)

ğŸ–¼ï¸ Medical Image Analysis using LLaMA 3 Vision (via Groq API)

ğŸ§  Doctor-like AI Responses using custom medical system prompts

ğŸ”Š Text-to-Speech (TTS) for AI voice responses

ğŸŒ Interactive Web UI built using Gradio

âš¡ Fast inference with Groqâ€™s high-performance LPU backend

ğŸ§° Tech Stack

| Layer                 | Tools / APIs                     |
| --------------------- | -------------------------------- |
| Programming Language  | Python                           |
| UI Framework          | Gradio                           |
| Speech-to-Text        | Whisper-large-v3 (Groq API)      |
| Image + Text Analysis | Meta LLaMA 3 Vision (Groq API)   |
| Text-to-Speech        | gTTS                             |
| Environment & Audio   | dotenv, Pydub, FFmpeg, PortAudio |
| Dependency Management | Pipenv                           |

âš™ï¸ Setup Instructions

1ï¸âƒ£ Clone the Repository
git clone https://github.com/yashika1004/AI-Doctor-with-Vision-and-Voice.git
cd AI-Doctor-with-Vision-and-Voice


2ï¸âƒ£ Set Environment Variables

Create a .env file in the project root:

GROQ_API_KEY=your_groq_api_key


3ï¸âƒ£ Install Dependencies
Option 1: Using Pipenv (Recommended)
pipenv install
pipenv shell

Option 2: Using pip
pip install -r requirements.txt


4ï¸âƒ£ Install Audio Dependencies (Windows Users)

FFmpeg
Download from: https://ffmpeg.org/download.html

Add FFmpeg to system PATH

PortAudio / PyAudio

pip install PyAudio-0.2.11-cp311-cp311-win_amd64.whl


ğŸ§ª How It Works â€“ Modular Architecture

| Phase | Module                    | Description                                |
| ----- | ------------------------- | ------------------------------------------ |
| 1     | `brain_of_the_doctor.py`  | Analyzes medical images using LLaMA Vision |
| 2     | `voice_of_the_patient.py` | Captures and transcribes patient speech    |
| 3     | `voice_of_the_doctor.py`  | Converts AI response into speech           |
| 4     | `gradio_app.py`           | Combines all modules into a single UI      |

ğŸ¨ User Flow

1ï¸âƒ£ Speak your symptoms
2ï¸âƒ£ Upload a relevant medical image
3ï¸âƒ£ AI processes voice + vision
4ï¸âƒ£ Receive text + spoken AI doctor response

ğŸ“¸ Demo Preview

UI allows:

ğŸ™ï¸ Voice input for symptoms

ğŸ–¼ï¸ Image upload (skin issues, reports, etc.)

ğŸ“„ AI-generated diagnosis-style response

ğŸ”Š Spoken medical explanation

ğŸŒŸ Project Inspiration

This project demonstrates how multimodal generative AI can be used to build:

Voice-enabled assistants

Vision-based medical insight systems

Accessible AI-driven healthcare demos

It explores the future of intelligent, empathetic AI health assistants.

ğŸ”® Future Improvements

ğŸŒ Multilingual support (Hindi, regional languages)

ğŸ—‚ï¸ User history & conversation logs

â˜ï¸ Deployment on Hugging Face / Streamlit Cloud

ğŸ” HIPAA/GDPR-safe sandbox mode

ğŸ“± Mobile-friendly UI

ğŸ‘©â€ğŸ’» Author

Yashika Srivastava
ğŸ“ B.Tech CSE (Data Science)
ğŸ”— GitHub: https://github.com/yashika1004

ğŸ“„ License

This project is released for educational and demonstration purposes only.
Not intended for real-world medical diagnosis or treatment.
=======
